import torch
import numpy as np
from noise_schedule import noise_related_calculate
from diff_utils import (ModelMeanType, ModelVarType, LossType, 
                    extract, mean_flat, normal_kl, 
                    discretized_gaussian_log_likelihood)


# -------------- åŸºç±» --------------
class GaussianDiffusion:
    def __init__(self, *, betas, model_mean_type, model_var_type, 
                 loss_type, rescale_timesteps=False):
        # å°†ä¼ å…¥çš„å‚æ•°æ³¨å†Œä¸º self å…¨å±€å˜é‡
        self.model_mean_type = model_mean_type
        self.model_var_type = model_var_type
        self.loss_type = loss_type
        self.rescale_timesteps = rescale_timesteps

        self.betas = np.asarray(betas)
        self.num_timesteps = int(betas.shape[0])

        # è·å–æ‰€æœ‰å™ªå£°è°ƒåº¦å‚æ•°ï¼Œå¹¶æ³¨å†Œä¸º self.xxx
        noise_schedule = noise_related_calculate(betas)
        for k, v in noise_schedule.items():
            setattr(self, k, v)

    def q_sample(self, x_start, t, noise=None):
        """ä»åŸå§‹å›¾åƒæ·»åŠ å™ªå£°, æ¨¡æ‹Ÿå‰å‘æ‰©æ•£è¿‡ç¨‹çš„é‡‡æ ·"""
        if noise is None:
            noise = torch.randn_like(x_start)
        assert noise.shape == x_start.shape

        return (
            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +
            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise
        )
    
    def q_posterior(self, x_start, x_t, t):
        """è®¡ç®—çœŸå®åéªŒçš„å‡å€¼å’Œæ–¹å·®, ç”¨äºé‡‡æ ·ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥éª¤ x_(t-1)"""
        posterior_mean = (
            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +
            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t
        )
        posterior_variance = extract(self.posterior_variance, t, x_t.shape)
        posterior_log_variance = extract(self.posterior_log_variance_clipped, t, x_t.shape)
        
        return posterior_mean, posterior_variance, posterior_log_variance
    
    def q_mean_variance(self, x_start, t):
        """å‘å‰åŠ å™ªåˆ†å¸ƒçš„ç›´æ¥è¡¨è¾¾å¼, è¾…åŠ©å‡½æ•°, åœ¨VLBè®¡ç®—ä¸­ä½¿ç”¨"""
        mean = (
            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start
        )
        variance = extract(1.0 - self.alphas_cumprod, t, x_start.shape)
        log_variance = extract(self.log_one_minus_alphas_cumprod, t, x_start.shape)
        return mean, variance, log_variance
    
    def predict_x0_from_eps(self, x_t, t, noise):
        """æ ¹æ®æ¨¡å‹é¢„æµ‹çš„å™ªå£° Îµï¼Œåæ¨å‡ºåŸå§‹å›¾åƒ x_0 çš„ä¼°è®¡å€¼"""
        return (
            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -
            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise
        )
    
    def predict_x0_from_xprev(self, x_t, t, xprev):
        """æ ¹æ® x_t å’Œ x_(t-1)ï¼Œåæ¨ x_0 çš„ä¼°è®¡å€¼"""
        return (  # (xprev - coef2 * x_t) / coef1
            extract(1.0 / self.posterior_mean_coef1, t, x_t.shape) * xprev - 
            extract(self.posterior_mean_coef2 / self.posterior_mean_coef1, t, x_t.shape)
            * x_t
        )
    
    def predict_eps_from_xstart(self, x_t, t, pred_xstart):
        """ DDIM ä¸­ä½¿ç”¨ï¼Œæ ¹æ®åŠ å™ªå…¬å¼ï¼Œåæ¨å™ªå£°"""
        return (
            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - pred_xstart
        ) / extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)
    
    def p_mean_variance(
        self, model, x, t, clip_denoised=True, denoised_fn=None, model_kwargs=None
    ):
        """è¿”å›æ¨¡å‹é¢„æµ‹çš„å™ªå£°å‡å€¼ã€æ–¹å·®ï¼ˆå›ºå®šã€å¯å­¦ä¹ ï¼‰"""
        if model_kwargs is None:
            model_kwargs = {}

        B, C = x.shape[:2] 
        assert t.shape == (B,)
        model_output = model(x, self._scale_timesteps(t), **model_kwargs)

        if self.model_var_type in [ModelVarType.LEARNED, ModelVarType.LEARNED_RANGE]:
            # --------------- å¯å­¦ä¹ æ–¹å·®ï¼Œé€šé“æ•°åŠ å€ ---------------
            assert model_output.shape == (B, C * 2, *x.shape[2:])
            model_output, model_var_values = torch.split(model_output, C, dim=1)
            
            if self.model_var_type == ModelVarType.LEARNED:
                model_log_variance = model_var_values
                model_variance = torch.exp(model_log_variance)
            else:
                min_log = extract(self.posterior_log_variance_clipped, t, x.shape)
                max_log = extract(torch.log(self.betas), t, x.shape)
                # The model_var_values is [-1, 1] for [min_var, max_var].
                frac = (model_var_values + 1) / 2
                model_log_variance = frac * max_log + (1 - frac) * min_log
                model_variance = torch.exp(model_log_variance)
        elif self.model_var_type in [ModelVarType.FIXED_LARGE, ModelVarType.FIXED_SMALL]:
            # --------------- å›ºå®šæ–¹å·® ---------------
            if self.model_var_type == ModelVarType.FIXED_LARGE:
                model_variance = np.append(self.posterior_variance[1], self.betas[1:])
                model_log_variance = np.log(np.append(self.posterior_variance[1], self.betas[1:]))
            else:
                model_variance = self.posterior_variance
                model_log_variance = self.posterior_log_variance_clipped

            model_variance = extract(model_variance, t, x.shape)
            model_log_variance = extract(model_log_variance, t, x.shape)
        else:
            raise NotImplementedError(f"Unknown model_var_type: {self.model_var_type}")

        def process_xstart(x):
            if denoised_fn is not None:
                x = denoised_fn(x)  # å¯é€‰çš„å»å™ªå‡½æ•°ï¼ˆå¦‚ super-resolution åå¤„ç†ï¼‰
            if clip_denoised:
                return x.clamp(-1, 1)  # ä¿è¯åƒç´ å€¼ä¸è¶Šç•Œ
            return x

        if self.model_mean_type == ModelMeanType.PREVIOUS_X:
            # --------------- é¢„æµ‹ x_t ---------------
            pred_xstart = process_xstart(
                self.predict_x0_from_xprev(x, t, model_output)
            )
            model_mean = model_output
        elif self.model_mean_type in [ModelMeanType.START_X, ModelMeanType.EPSILON]:
            # --------------- é¢„æµ‹ x_0 æˆ– epsilon ---------------
            if self.model_mean_type == ModelMeanType.START_X:
                pred_xstart = process_xstart(model_output)
            else:
                pred_xstart = process_xstart(
                    self.predict_x0_from_eps(x, t, model_output)
                )
            model_mean, _, _ = self.q_posterior(pred_xstart, x, t)
        else:
            raise NotImplementedError(self.model_mean_type)

        assert (model_mean.shape == model_log_variance.shape == pred_xstart.shape == x.shape)
        return {
            "mean": model_mean,
            "variance": model_variance,
            "log_variance": model_log_variance,
            "pred_xstart": pred_xstart,
        }
    
    def _vb_terms_bpd(
        self, model, x_start, x_t, t, clip_denoised=True, model_kwargs=None
    ):
        """ ä¼°ç®—å˜åˆ†ä¸‹ç•Œ (Variational Lower Bound, VLB) """
        # --------------- è·å– çœŸå®åéªŒåˆ†å¸ƒ / æ¨¡å‹é¢„æµ‹åˆ†å¸ƒ çš„å‡å€¼å’Œæ–¹å·® ---------------
        true_mean, _, true_log_variance_clipped = self.q_posterior(x_start, x_t, t)
        out = self.p_mean_variance(
            model, x_t, t, clip_denoised=clip_denoised, model_kwargs=model_kwargs
        )
        # --------------- è®¡ç®— KL æ•£åº¦ï¼›è½¬æ¢å•ä½ nat å˜ bit ---------------
        kl = normal_kl(
            true_mean, true_log_variance_clipped, out["mean"], out["log_variance"]
        )
        kl = mean_flat(kl) / np.log(2.0)

        # --------------- è®¡ç®—è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼›è½¬æ¢å•ä½ nat å˜ bit ---------------
        decoder_nll = -discretized_gaussian_log_likelihood(
            x_start, means=out["mean"], log_scales=0.5 * out["log_variance"]
        )
        assert decoder_nll.shape == x_start.shape
        decoder_nll = mean_flat(decoder_nll) / np.log(2.0)

        # --------------- åœ¨ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥è¿”å›è§£ç å™¨ NLLï¼Œå¦åˆ™è¿”å› KL ---------------
        output = torch.where((t == 0), decoder_nll, kl)
        return {"output": output, "pred_xstart": out["pred_xstart"]}
    
    def _scale_timesteps(self, t):
        if self.rescale_timesteps:
            return t.float() * (1000.0 / self.num_timesteps)
        return t

    def training_losses(self, model, x_start, t, model_kwargs=None, noise=None):
        """æŸå¤±å‡½æ•°è°ƒç”¨å…¥å£, ç”¨äºè®¡ç®—å•ä¸ªæ—¶é—´æ­¥ä¸‹çš„æŸå¤±å€¼"""
        if model_kwargs is None:
            model_kwargs = {}
        if noise is None:
            noise = torch.randn_like(x_start)
        x_t = self.q_sample(x_start, t, noise=noise)  # åŠ å™ªéŸ³å¾—åˆ° x_t

        terms = {}

        if self.loss_type == LossType.KL or self.loss_type == LossType.RESCALED_KL:
            terms["loss"] = self._vb_terms_bpd(
                model=model, x_start=x_start, x_t=x_t, t=t,
                clip_denoised=False, model_kwargs=model_kwargs,
            )["output"]
            if self.loss_type == LossType.RESCALED_KL:
                # loss å°ºåº¦è·Ÿ MSE ç±»å‹å¯¹é½
                terms["loss"] *= self.num_timesteps
        elif self.loss_type == LossType.MSE or self.loss_type == LossType.RESCALED_MSE:
            model_output = model(x_t, self._scale_timesteps(t), **model_kwargs)
            
            # ------------ å¦‚æœæ–¹å·®å¯å­¦ä¹ ï¼Œä½¿ç”¨ KL/NLL è®¡ç®— ------------
            if self.model_var_type in [ModelVarType.LEARNED, ModelVarType.LEARNED_RANGE]:
                B, C = x_t.shape[:2]
                assert model_output.shape == (B, C * 2, *x_t.shape[2:])
                model_output, model_var_values = torch.split(model_output, C, dim=1)
                # åˆ©ç”¨å˜å¼‚çº¦æŸå­¦ä¹ æ–¹å·®ï¼Œä½†ä¸è¦è®©å®ƒå½±å“æˆ‘ä»¬å¯¹å¹³å‡å€¼çš„é¢„æµ‹ã€‚
                frozen_out = torch.cat([model_output.detach(), model_var_values], dim=1)
                terms["vb"] = self._vb_terms_bpd(
                    model=lambda *args, r=frozen_out: r,
                    x_start=x_start, x_t=x_t, t=t,
                    clip_denoised=False,
                )["output"]
                if self.loss_type == LossType.RESCALED_MSE:
                    # ç¼©æ”¾ä¿®æ­£é¡¹ï¼Œä¿æŒ vb_loss å’Œ mes_loss çš„æ•°å€¼ä¸€è‡´æ€§
                    terms["vb"] *= self.num_timesteps / 1000.0

            # ------------ ä½¿ç”¨ MSE è®¡ç®—å‡å€¼ ------------
            target = {
                ModelMeanType.PREVIOUS_X: self.q_posterior(
                    x_start=x_start, x_t=x_t, t=t
                )[0],
                ModelMeanType.START_X: x_start,
                ModelMeanType.EPSILON: noise,
            }[self.model_mean_type]
            assert model_output.shape == target.shape == x_start.shape
            terms["mse"] = mean_flat((target - model_output) ** 2)

            # ------------ å¦‚æœå¯å­¦ä¹ æ–¹å·® vb å­˜åœ¨ï¼Œåˆå¹¶ MSE ------------
            if "vb" in terms:
                terms["loss"] = terms["mse"] + terms["vb"]
            else:
                terms["loss"] = terms["mse"]
        else:
            raise NotImplementedError(self.loss_type)

        return terms
    
    def _prior_bpd(self, x_start):
        """
        è·å–å˜åˆ†ä¸‹é™çš„å…ˆéªŒ KL é¡¹ï¼Œå•ä½ä¸ºæ¯”ç‰¹/æ¯”ç‰¹ã€‚è¯¥é¡¹æ— æ³•ä¼˜åŒ–ï¼Œå› ä¸ºå®ƒåªå–å†³äºç¼–ç å™¨ã€‚

        :param x_start: the [N x C x ...] tensor of inputs.
        :return: a batch of [N] KL values (in bits), one per batch element.
        """
        batch_size = x_start.shape[0]
        t = torch.tensor([self.num_timesteps - 1] * batch_size, device=x_start.device)
        qt_mean, _, qt_log_variance = self.q_mean_variance(x_start, t)
        kl_prior = normal_kl(
            mean1=qt_mean, logvar1=qt_log_variance, mean2=0.0, logvar2=0.0
        )
        return mean_flat(kl_prior) / np.log(2.0)

    def calc_bpd_loop(self, model, x_start, clip_denoised=True, model_kwargs=None):
        """
        è®¡ç®—æ•´ä¸ªå˜åˆ†ä¸‹é™ï¼ˆä»¥æ¯æ¯”ç‰¹ä¸ºå•ä½ï¼‰ä»¥åŠå…¶ä»–ç›¸å…³æ•°é‡ã€‚

        :param model: è¯„ä¼°æŸå¤±çš„æ¨¡å‹
        :param x_start: the [N x C x ...] tensor of inputs.
        :param clip_denoised: if True, clip denoised samples.
        :param model_kwargs: if not None, a dict of extra keyword arguments to
            pass to the model. This can be used for conditioning.

        :return: a dict containing the following keys:
                 - total_bpd: æ¯ä¸ªæ‰¹æ¬¡å…ƒç´ çš„æ€»å˜åˆ†ä¸‹é™ã€‚
                 - prior_bpd: ä¸‹é™ä¸­çš„å‰é¡¹ã€‚
                 - vb: ä¸‹ç•Œé¡¹çš„ [N x T] å¼ é‡ã€‚
                 - xstart_mse: æ¯ä¸ªæ—¶é—´æ­¥çš„ x_0 MSE çš„ [N x T] å¼ é‡ã€‚
                 - mse: æ¯ä¸ªæ—¶é—´æ­¥çš„Îµ MSE çš„ [N x T] å¼ é‡ã€‚
        """
        device = x_start.device
        batch_size = x_start.shape[0]

        vb = []
        xstart_mse = []
        mse = []
        for t in list(range(self.num_timesteps))[::-1]:
            t_batch = torch.tensor([t] * batch_size, device=device)
            noise = torch.randn_like(x_start)
            x_t = self.q_sample(x_start=x_start, t=t_batch, noise=noise)
            # Calculate VLB term at the current timestep
            with torch.no_grad():
                out = self._vb_terms_bpd(
                    model,
                    x_start=x_start,
                    x_t=x_t,
                    t=t_batch,
                    clip_denoised=clip_denoised,
                    model_kwargs=model_kwargs,
                )
            vb.append(out["output"])
            xstart_mse.append(mean_flat((out["pred_xstart"] - x_start) ** 2))
            eps = self._predict_eps_from_xstart(x_t, t_batch, out["pred_xstart"])
            mse.append(mean_flat((eps - noise) ** 2))

        vb = torch.stack(vb, dim=1)
        xstart_mse = torch.stack(xstart_mse, dim=1)
        mse = torch.stack(mse, dim=1)

        prior_bpd = self._prior_bpd(x_start)
        total_bpd = vb.sum(dim=1) + prior_bpd
        return {
            "total_bpd": total_bpd,
            "prior_bpd": prior_bpd,
            "vb": vb,
            "xstart_mse": xstart_mse,
            "mse": mse,
        }
    
    
# -------------- DDPM åŸå§‹é‡‡æ ·å™¨ --------------
class SamplerDDPM:
    def __init__(self, diffusion: GaussianDiffusion):
        self.diffusion = diffusion

        # ç”¨åˆ°çš„å±æ€§ï¼Œé‡æ–°å»ºç«‹ç´¢å¼•å¼•ç”¨ï¼Œä¸ä¼šé¢å¤–å ç”¨æ˜¾å­˜
        self.p_mean_variance = diffusion.p_mean_variance
        self.num_timesteps = diffusion.num_timesteps

    def p_sample(
        self, model, x_t, t, clip_denoised=True, denoised_fn=None, model_kwargs=None
    ):
        """ Sample x_{t-1} from the model at the given timestep. """
        out = self.p_mean_variance(
            model, x_t, t, model_kwargs=model_kwargs,
            clip_denoised=clip_denoised, denoised_fn=denoised_fn,
        )

        noise = torch.randn_like(x_t)
        nonzero_mask = ((t != 0).float().view(-1, *([1] * (len(x_t.shape) - 1))))
        sample = out["mean"] + nonzero_mask * torch.exp(0.5 * out["log_variance"]) * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}
    
    def p_sample_loop(
        self, model, shape, device=None, noise=None, progress=False,
        clip_denoised=True, denoised_fn=None, model_kwargs=None,
    ):
        """ ä»çº¯å™ªå£°å¼€å§‹åå¤è°ƒç”¨ p_sample é‡‡æ ·å‡ºæœ€ç»ˆå›¾åƒ """
        if noise is not None:
            x_t = noise
        else:
            x_t = torch.randn(shape, device=device)
        
        indices = reversed(range(self.num_timesteps))
        if progress:
            from tqdm.auto import tqdm
            indices = tqdm(indices)

        with torch.no_grad():
            for i in indices:
                t = torch.full((shape[0],), i, device=device, dtype=torch.long)
                x_t = self.p_sample(
                    model, x_t, t, model_kwargs=model_kwargs,
                    clip_denoised=clip_denoised, denoised_fn=denoised_fn
                )

        return x_t["sample"]
    
    def sample(
        self, model, image_size, batch_size=16, clip_denoised=True, model_kwargs=None
    ):
        """å¤–éƒ¨è°ƒç”¨å…¥å£ï¼Œå°è£… p_sample_loop"""
        shape = (batch_size, 3, image_size, image_size)
        device = next(model.parameters()).device  # ğŸ‘ˆ è‡ªåŠ¨è·å–æ¨¡å‹æ‰€åœ¨è®¾å¤‡
        return self.p_sample_loop(
            model, shape, device, 
            clip_denoised=clip_denoised, model_kwargs=model_kwargs
        )
    
# -------------- DDIM åŠ é€Ÿé‡‡æ ·å™¨ --------------
class SamplerDDIM:
    def __init__(self, diffusion: GaussianDiffusion):
        self.diffusion = diffusion
        
        # -------------- ddim_sampleã€ddim_reverse_sample --------------
        self.p_mean_variance = diffusion.p_mean_variance
        self.predict_eps_from_xstart = diffusion.predict_eps_from_xstart
        self.alphas_cumprod = diffusion.alphas_cumprod
        self.alphas_cumprod_prev = diffusion.alphas_cumprod_prev
        self.alphas_cumprod_next = diffusion.alphas_cumprod_next
        self.num_timesteps = diffusion.num_timesteps

    def ddim_reverse_sample(
        self, model, x, t, eta=0.0,
        clip_denoised=True, denoised_fn=None, model_kwargs=None,
    ):
        """ ç”¨äº åæ¨åŠ å™ª è½¨è¿¹ï¼Œè®¡ç®— x_(t+1) """
        assert eta == 0.0, "Reverse ODE only for deterministic path"
        out = self.p_mean_variance(
            model, x, t, clip_denoised=clip_denoised,
            denoised_fn=denoised_fn, model_kwargs=model_kwargs,
        )

        # åœ¨ä½¿ç”¨ x_start æˆ– x_prev é¢„æµ‹çš„æƒ…å†µä¸‹ï¼Œé‡æ–°å¾—å‡ºÎµ
        eps = self.predict_eps_from_xstart(x, t, out["pred_xstart"])
        alpha_bar_next = extract(self.alphas_cumprod_next, t, x.shape)
        mean_pred = (
            out["pred_xstart"] * torch.sqrt(alpha_bar_next)
            + torch.sqrt(1 - alpha_bar_next) * eps
        )

        return {"sample": mean_pred, "pred_xstart": out["pred_xstart"]}

    def ddim_sample(
        self, model, x, t, eta=0.0,
        clip_denoised=True, denoised_fn=None, model_kwargs=None,
    ):
        """ Sample x_{t-1} from the model using DDIM. """
        # -------------- è¿”å› meanã€varianceã€log_varianceã€pred_xstart å­—å…¸ --------------
        out = self.p_mean_variance(
            model, x, t, clip_denoised=clip_denoised,
            denoised_fn=denoised_fn, model_kwargs=model_kwargs,
        )
        # -------------- é‡æ–°è®¡ç®—å™ªå£°åˆ†å¸ƒçš„æ–¹å·®ï¼Œä½¿ç”¨ eta æ§åˆ¶éšæœºç¨‹åº¦ --------------
        alpha_bar = extract(self.alphas_cumprod, t, x.shape)
        alpha_bar_prev = extract(self.alphas_cumprod_prev, t, x.shape)
        sigma = (
            eta
            * torch.sqrt((1 - alpha_bar_prev) / (1 - alpha_bar))
            * torch.sqrt(1 - alpha_bar / alpha_bar_prev)
        )
        # -------------- åœ¨ä½¿ç”¨ x_start æˆ– x_prev é¢„æµ‹çš„æƒ…å†µä¸‹ï¼Œé‡æ–°å¾—å‡ºÎµ --------------
        eps = self.predict_eps_from_xstart(x, t, out["pred_xstart"])
        mean_pred = (
            out["pred_xstart"] * torch.sqrt(alpha_bar_prev)
            + torch.sqrt(1 - alpha_bar_prev - sigma ** 2) * eps
        )

        noise = torch.randn_like(x)
        nonzero_mask = ((t != 0).float().view(-1, *([1] * (len(x.shape) - 1))))
        sample = mean_pred + nonzero_mask * sigma * noise
        return {"sample": sample, "pred_xstart": out["pred_xstart"]}
    
    def sample_loop(
        self, model, shape, device=None, noise=None, progress=False,
        clip_denoised=True, denoised_fn=None, model_kwargs=None, eta=0.0,
    ):
        """ ä½¿ç”¨ DDIM å¯¹æ¨¡å‹è¿›è¡Œé‡‡æ ·ï¼Œå¹¶ä» DDIM çš„æ¯ä¸ªæ—¶é—´æ­¥äº§ç”Ÿä¸­é—´æ ·æœ¬ """
        if noise is not None:
            img = noise
        else:
            img = torch.randn(*shape, device=device)
        
        indices = reversed(range(self.num_timesteps))
        if progress:
            from tqdm.auto import tqdm
            indices = tqdm(indices)

        with torch.no_grad():
            for i in indices:
                t = torch.full((shape[0],), i, device=device, dtype=torch.long)
                img = self.ddim_sample(
                    model, img, t, eta=eta, model_kwargs=model_kwargs,
                    clip_denoised=clip_denoised, denoised_fn=denoised_fn
                )

        return img["sample"]
    
    def sample(
        self, model, image_size, batch_size=16, clip_denoised=True, model_kwargs=None
    ):
        """å¤–éƒ¨è°ƒç”¨å…¥å£ï¼Œå°è£… sample_loop"""
        shape = (batch_size, 3, image_size, image_size)
        device = next(model.parameters()).device
        return self.sample_loop(
            model, shape, device, 
            clip_denoised=clip_denoised, model_kwargs=model_kwargs
        )
    
    
